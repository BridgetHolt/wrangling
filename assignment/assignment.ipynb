{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling\n",
        "## `! git clone https://github.com/DS3001/wrangling`\n",
        "## Do Q2, and one of Q1 or Q3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "1. Read the abstract. What is this paper about?\n",
        "\n",
        "It covers elements of data cleaning that are small but important for the process on the whole, called data tidying. It covers the importance of having columns for varible, rows for observations, etc.\n",
        "\n",
        "2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
        "\n",
        "It makes it easier for data scientists to understand/ they don't have to reinvent the wheel every time. It facilitates the inital exploration of the data and It makes it easier for data scientists to work together as they are all cleaning useing the same standard.\n",
        "\n",
        "3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, itâ€™s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
         "\n",
         "The first sentance means that tidy data sets all have a the same handful of properties that make them the same/easy to understand and that messy data all has its own unique problems that need to be solved. The second sentance means that data frames can be more complicated then expected. The idea of rows and columns is relatively straight forward but figuring out where each individual observation should be place and where the rows and columns are may be more complicated.\n", 
         "\n",
        "4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
        "\n",
        "Wickham defines valuse as usally either strings or numeric values that make up a data set. He defines variables as somthing that holds all the values that are measures of the same attribute by units. An observation is defined as all values that measured on the same unit (so like one person).\n",
        "\n",
        "5. How is \"Tidy Data\" defined in section 2.3?\n",
        "\n",
        "Tidy Data is defined as the standard way of mapping the meaning of the dataset to its structure. Some of the important features of it include Each variable forms a column, Each observation forms a row, each type of observational unit.\n",
        "\n",
        "6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
        "\n",
        "The five most common problems with messy data sets are Column headers are values, not variable names, Multipule variables are stored in one column, Variables are stored in both rows and columns, Multipule types of observational units are stored in the same table, and a single observational unit is stored in multipule tables. The data in table four is messy becouse the column headers are values. Income needs to be its own column instead of column headers. Melting a dataset means turning columns into row.\n",
        "\n",
        "7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
        "\n",
        "Table 11 is messy becouse it has days listed at the top as columns even though they are values. Table 12 makes the days into one column but that column holds other variable names which means it is still not clean. Then in table 12b they break them up into tmin and tmax columns so that no column is filled with values and not variables.\n",
        "\n",
        "8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
        "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
      "metadata": {
        "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
      },
      "source": [
        "**Q3.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
        "\n",
        "1. How did the most recent US Census gather data on race?\n",
        "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
        "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
        "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
        "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
        "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
